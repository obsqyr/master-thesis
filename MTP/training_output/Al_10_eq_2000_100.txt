MTPR from untrained_mtps/10.mtp, Database: cfg_train_eq/Al_train_100_eq_2000.cfg
Random initialization of radial coefficients
Rescaling...
   scaling = 0.833333333333333, condition number = 12950.7663672794
   scaling = 0.909090909090909, condition number = 16808.407263712
   scaling = 1, condition number = 22365.6285516356
   scaling = 1.1, condition number = 28374.7715055317
   scaling = 1.2, condition number = 33762.2930931398
Rescaling to 0.833333333333333... done
Rescaling...
   scaling = 0.694444444444445, condition number = 7501.10457242009
   scaling = 0.757575757575758, condition number = 9734.10393477148
   scaling = 0.833333333333333, condition number = 12950.787791867
   scaling = 0.916666666666667, condition number = 17231.6643615488
   scaling = 1, condition number = 22365.6285516356
Rescaling to 0.694444444444445... done
Rescaling...
   scaling = 0.578703703703704, condition number = 4346.28999177899
   scaling = 0.631313131313131, condition number = 5639.01768120902
   scaling = 0.694444444444445, condition number = 7501.10457242009
   scaling = 0.763888888888889, condition number = 9979.10382847718
   scaling = 0.833333333333333, condition number = 12950.787791867
Rescaling to 0.578703703703704... done
Rescaling...
   scaling = 0.482253086419753, condition number = 2519.70313003003
   scaling = 0.526094276094276, condition number = 3268.21196273297
   scaling = 0.578703703703704, condition number = 4346.28999177899
   scaling = 0.636574074074074, condition number = 5780.84531196454
   scaling = 0.694444444444445, condition number = 7501.10457242009
Rescaling to 0.482253086419753... done
Rescaling...
   scaling = 0.401877572016461, condition number = 1461.91863397977
   scaling = 0.43841189674523, condition number = 1895.41592110281
   scaling = 0.482253086419753, condition number = 2519.70313003003
   scaling = 0.530478395061729, condition number = 3350.32853226275
   scaling = 0.578703703703704, condition number = 4346.28999177899
Rescaling to 0.401877572016461... done
Rescaling...
   scaling = 0.334897976680384, condition number = 849.165539516393
   scaling = 0.365343247287692, condition number = 1100.30799872213
   scaling = 0.401877572016461, condition number = 1461.91863397977
   scaling = 0.442065329218107, condition number = 1942.97054627045
   scaling = 0.482253086419753, condition number = 2519.70317352235
Rescaling to 0.334897976680384... done
Rescaling...
   scaling = 0.279081647233653, condition number = 494.059346885402
   scaling = 0.304452706073077, condition number = 639.624939327066
   scaling = 0.334897976680384, condition number = 849.165539516393
   scaling = 0.368387774348423, condition number = 1127.8556543186
   scaling = 0.401877572016461, condition number = 1461.91863397977
Rescaling to 0.279081647233653... done
Rescaling...
   scaling = 0.232568039361378, condition number = 295.832389300918
   scaling = 0.25371058839423, condition number = 372.570176494803
   scaling = 0.279081647233653, condition number = 494.059346885402
   scaling = 0.306989811957019, condition number = 655.590089636799
   scaling = 0.334897976680384, condition number = 849.165539516393
Rescaling to 0.232568039361378... done
Rescaling...
   scaling = 0.193806699467815, condition number = 207.764054594325
   scaling = 0.211425490328525, condition number = 245.803775581324
   scaling = 0.232568039361378, condition number = 295.832389300918
   scaling = 0.255824843297516, condition number = 381.828212714733
   scaling = 0.279081647233653, condition number = 494.059346885402
Rescaling to 0.193806699467815... done
Rescaling...
   scaling = 0.161505582889846, condition number = 146.657902066633
   scaling = 0.176187908607104, condition number = 173.046992804894
   scaling = 0.193806699467815, condition number = 207.764054594325
   scaling = 0.213187369414596, condition number = 249.790154226217
   scaling = 0.232568039361378, condition number = 295.832389300918
Rescaling to 0.161505582889846... done
Rescaling...
   scaling = 0.134587985741538, condition number = 111.976667370491
   scaling = 0.146823257172587, condition number = 124.532811852283
   scaling = 0.161505582889846, condition number = 146.657902066633
   scaling = 0.17765614117883, condition number = 175.813001919213
   scaling = 0.193806699467815, condition number = 207.764057318331
Rescaling to 0.134587985741538... done
Rescaling...
   scaling = 0.112156654784615, condition number = 74.9846842183931
   scaling = 0.122352714310489, condition number = 87.6298488548204
   scaling = 0.134587985741538, condition number = 111.976667370491
   scaling = 0.148046784315692, condition number = 125.435469893667
   scaling = 0.161505582889846, condition number = 146.657902066633
Rescaling to 0.112156654784615... done
Rescaling...
   scaling = 0.0934638789871793, condition number = 54.7744660910647
   scaling = 0.101960595258741, condition number = 63.4802768239778
   scaling = 0.112156654784615, condition number = 74.9846842183931
   scaling = 0.123372320263077, condition number = 88.9567237226279
   scaling = 0.134587985741538, condition number = 111.976667370491
Rescaling to 0.0934638789871793... done
Rescaling...
   scaling = 0.0778865658226494, condition number = 36.6784608492102
   scaling = 0.0849671627156175, condition number = 45.8202017220975
   scaling = 0.0934638789871793, condition number = 54.7744660910647
   scaling = 0.102810266885897, condition number = 64.395090958684
   scaling = 0.112156654784615, condition number = 74.9846842183931
Rescaling to 0.0778865658226494... done
Rescaling...
   scaling = 0.0649054715188745, condition number = 23.5973260113995
   scaling = 0.0708059689296813, condition number = 28.9002235275692
   scaling = 0.0778865658226494, condition number = 36.6784608492102
   scaling = 0.0856752224049144, condition number = 46.8191623087856
   scaling = 0.0934638789871793, condition number = 54.7744673829884
Rescaling to 0.0649054715188745... done
Rescaling...
   scaling = 0.0540878929323954, condition number = 15.8616745767411
   scaling = 0.0590049741080677, condition number = 19.0532129018366
   scaling = 0.0649054715188745, condition number = 23.5973260113995
   scaling = 0.071396018670762, condition number = 29.5769415602047
   scaling = 0.0778865658226494, condition number = 36.6784606683308
Rescaling to 0.0540878929323954... done
Rescaling...
   scaling = 0.0450732441103295, condition number = 11.2754050681288
   scaling = 0.0491708117567231, condition number = 13.1679656147061
   scaling = 0.0540878929323954, condition number = 15.8616745767411
   scaling = 0.059496682225635, condition number = 19.4012888621194
   scaling = 0.0649054715188745, condition number = 23.5973260113995
Rescaling to 0.0450732441103295... done
Rescaling...
   scaling = 0.0375610367586079, condition number = 8.56590546101979
   scaling = 0.0409756764639359, condition number = 9.68065610722901
   scaling = 0.0450732441103295, condition number = 11.2754050681288
   scaling = 0.0495805685213625, condition number = 13.3743811441173
   scaling = 0.0540878929323954, condition number = 15.8616743272895
Rescaling to 0.0375610367586079... done
Rescaling...
   scaling = 0.0313008639655066, condition number = 8.3409954097604
   scaling = 0.03414639705328, condition number = 8.33989455555536
   scaling = 0.0375610367586079, condition number = 8.56590546101979
   scaling = 0.0413171404344687, condition number = 9.8026438082282
   scaling = 0.0450732441103295, condition number = 11.2754050681288
Rescaling to 0.03414639705328... done
Rescaling...
   scaling = 0.0284553308777333, condition number = 8.50781639654637
   scaling = 0.0310421791393454, condition number = 8.34858215029199
   scaling = 0.03414639705328, condition number = 8.33989455555536
   scaling = 0.037561036758608, condition number = 8.56590503264285
   scaling = 0.0409756764639359, condition number = 9.68065610722901
Rescaling to 0.03414639705328... done
Pre-training started
MTPR parallel training started
BFGS iter 0: f=0.00276385
BFGS iter 1: f=0.00276344
BFGS iter 2: f=0.00275359
BFGS iter 3: f=0.00274351
BFGS iter 4: f=0.00272647
BFGS iter 5: f=0.00272365
BFGS iter 6: f=0.00271851
BFGS iter 7: f=0.00271224
BFGS iter 8: f=0.00270369
BFGS iter 9: f=0.00266797
BFGS iter 10: f=0.00266173
BFGS iter 11: f=0.00265083
BFGS iter 12: f=0.00263928
BFGS iter 13: f=0.00263049
BFGS iter 14: f=0.00262591
BFGS iter 15: f=0.00262121
BFGS iter 16: f=0.00260575
BFGS iter 17: f=0.00258121
BFGS iter 18: f=0.0025763
BFGS iter 19: f=0.00256509
BFGS iter 20: f=0.00255376
BFGS iter 21: f=0.00254111
BFGS iter 22: f=0.00253471
BFGS iter 23: f=0.00252757
BFGS iter 24: f=0.00252237
BFGS iter 25: f=0.00251636
BFGS iter 26: f=0.00250145
BFGS iter 27: f=0.00248645
BFGS iter 28: f=0.00246224
BFGS iter 29: f=0.00245152
BFGS iter 30: f=0.00244696
BFGS iter 31: f=0.00244507
BFGS iter 32: f=0.00244341
BFGS iter 33: f=0.00244228
BFGS iter 34: f=0.00244147
BFGS iter 35: f=0.00244071
BFGS iter 36: f=0.00243906
BFGS iter 37: f=0.00243327
BFGS iter 38: f=0.00243021
BFGS iter 39: f=0.00242099
BFGS iter 40: f=0.00240906
BFGS iter 41: f=0.00239498
BFGS iter 42: f=0.00238484
BFGS iter 43: f=0.00232222
BFGS iter 44: f=0.0023134
BFGS iter 45: f=0.00230468
BFGS iter 46: f=0.00229653
BFGS iter 47: f=0.0022894
BFGS iter 48: f=0.00228557
BFGS iter 49: f=0.00227979
BFGS iter 50: f=0.00207619
BFGS iter 51: f=0.00207529
BFGS iter 52: f=0.00207445
BFGS iter 53: f=0.00207254
BFGS iter 54: f=0.00206865
BFGS iter 55: f=0.00206575
BFGS iter 56: f=0.00206299
BFGS iter 57: f=0.00205833
BFGS iter 58: f=0.00205329
BFGS iter 59: f=0.00204424
BFGS iter 60: f=0.0020417
BFGS iter 61: f=0.00203965
BFGS iter 62: f=0.00203117
BFGS iter 63: f=0.00202314
BFGS iter 64: f=0.00201168
BFGS iter 65: f=0.00200037
BFGS iter 66: f=0.00198777
BFGS iter 67: f=0.00198473
BFGS iter 68: f=0.00198133
BFGS iter 69: f=0.00197684
BFGS iter 70: f=0.00197057
BFGS iter 71: f=0.00196159
BFGS iter 72: f=0.00195543
BFGS iter 73: f=0.00195062
BFGS iter 74: f=0.00194223
step limit reached
MTPR training ended
Rescaling...
   scaling = 0.0284553308777333, condition number = 23.5667255930312
   scaling = 0.0310421791393454, condition number = 28.290052381654
   scaling = 0.03414639705328, condition number = 29.536536973743
   scaling = 0.037561036758608, condition number = 31.0743598010092
   scaling = 0.0409756764639359, condition number = 32.5161431879699
Rescaling to 0.0284553308777333... done
Rescaling...
   scaling = 0.0237127757314444, condition number = 16.1267624471735
   scaling = 0.0258684826161212, condition number = 19.317496983426
   scaling = 0.0284553308777333, condition number = 23.4767678997997
   scaling = 0.0313008639655066, condition number = 28.2686430624182
   scaling = 0.03414639705328, condition number = 29.5365482200366
Rescaling to 0.0237127757314444... done
Rescaling...
   scaling = 0.0197606464428703, condition number = 11.5051347000467
   scaling = 0.0215570688467676, condition number = 13.355026846708
   scaling = 0.0237127757314444, condition number = 16.126749636142
   scaling = 0.0260840533045889, condition number = 19.3576198867789
   scaling = 0.0284553308777333, condition number = 23.4641014314554
Rescaling to 0.0197606464428703... done
Rescaling...
   scaling = 0.0164672053690586, condition number = 15.880636567379
   scaling = 0.017964224038973, condition number = 12.9857408987174
   scaling = 0.0197606464428703, condition number = 11.5051310649028
   scaling = 0.0217367110871574, condition number = 13.5345160261701
   scaling = 0.0237127757314444, condition number = 16.127456155245
Rescaling to 0.0197606464428703... done
Pre-training ended
BFGS iterations count set to 1000
BFGS convergence tolerance set to 0.001
Energy weight: 1
Force weight: 0.01
Stress weight: 0.001
MTPR parallel training started
BFGS iter 0: f=0.00172614
BFGS iter 1: f=0.00172536
BFGS iter 2: f=0.00172383
BFGS iter 3: f=0.0017226
BFGS iter 4: f=0.00171816
BFGS iter 5: f=0.00168951
BFGS iter 6: f=0.00168121
BFGS iter 7: f=0.00167726
BFGS iter 8: f=0.00167598
BFGS iter 9: f=0.0016742
BFGS iter 10: f=0.00166494
BFGS iter 11: f=0.00166157
BFGS iter 12: f=0.00166001
BFGS iter 13: f=0.00165756
BFGS iter 14: f=0.00162919
BFGS iter 15: f=0.00162322
BFGS iter 16: f=0.00162134
BFGS iter 17: f=0.00162031
BFGS iter 18: f=0.00161974
BFGS iter 19: f=0.00161957
BFGS iter 20: f=0.0016192
BFGS iter 21: f=0.00161756
BFGS iter 22: f=0.00161448
BFGS iter 23: f=0.00161416
BFGS iter 24: f=0.00161389
BFGS iter 25: f=0.00161351
BFGS iter 26: f=0.0016123
BFGS iter 27: f=0.00160977
BFGS iter 28: f=0.00160739
BFGS iter 29: f=0.00160659
BFGS iter 30: f=0.00160628
BFGS iter 31: f=0.00160614
BFGS iter 32: f=0.00160586
BFGS iter 33: f=0.00160532
BFGS iter 34: f=0.00160496
BFGS iter 35: f=0.00160404
BFGS iter 36: f=0.00159713
BFGS iter 37: f=0.0015944
BFGS iter 38: f=0.001583
BFGS iter 39: f=0.00158059
BFGS iter 40: f=0.00156857
BFGS iter 41: f=0.00155858
BFGS iter 42: f=0.00154914
BFGS iter 43: f=0.00154542
BFGS iter 44: f=0.00153825
BFGS iter 45: f=0.00153703
BFGS iter 46: f=0.00153651
BFGS iter 47: f=0.00153635
BFGS iter 48: f=0.00153616
BFGS iter 49: f=0.00153547
BFGS iter 50: f=0.00150575
BFGS iter 51: f=0.00150321
BFGS iter 52: f=0.00150264
BFGS iter 53: f=0.0015023
BFGS iter 54: f=0.00150214
BFGS iter 55: f=0.00150206
BFGS iter 56: f=0.00150201
BFGS iter 57: f=0.00150187
BFGS iter 58: f=0.00150177
BFGS iter 59: f=0.00150153
BFGS iter 60: f=0.00150103
BFGS iter 61: f=0.00149806
BFGS iter 62: f=0.00149469
BFGS iter 63: f=0.00149405
BFGS iter 64: f=0.00149396
BFGS iter 65: f=0.00149381
BFGS iter 66: f=0.00149286
BFGS iter 67: f=0.00149092
BFGS iter 68: f=0.00148926
BFGS iter 69: f=0.00148772
BFGS iter 70: f=0.0014869
BFGS iter 71: f=0.00148593
BFGS iter 72: f=0.00148535
BFGS iter 73: f=0.00148465
BFGS iter 74: f=0.001484
BFGS iter 75: f=0.00148332
BFGS iter 76: f=0.0014831
BFGS iter 77: f=0.00148261
BFGS iter 78: f=0.00148201
BFGS iter 79: f=0.00148111
BFGS iter 80: f=0.0014809
BFGS iter 81: f=0.00148
BFGS iter 82: f=0.00147887
BFGS iter 83: f=0.00147722
BFGS iter 84: f=0.00147602
BFGS iter 85: f=0.00147547
BFGS iter 86: f=0.00147509
BFGS iter 87: f=0.00147447
BFGS iter 88: f=0.00147404
BFGS iter 89: f=0.00147373
BFGS iter 90: f=0.00147368
BFGS iter 91: f=0.00147364
BFGS iter 92: f=0.00147363
BFGS iter 93: f=0.00147362
BFGS iter 94: f=0.00147356
BFGS iter 95: f=0.00147285
BFGS iter 96: f=0.00147109
BFGS iter 97: f=0.00146964
BFGS iter 98: f=0.00146911
BFGS iter 99: f=0.00146894
BFGS iter 100: f=0.00144853
BFGS iter 101: f=0.00144753
BFGS iter 102: f=0.00144642
BFGS iter 103: f=0.00144584
BFGS iter 104: f=0.0014454
BFGS iter 105: f=0.00144494
BFGS iter 106: f=0.0014446
BFGS iter 107: f=0.00144416
BFGS iter 108: f=0.00144374
BFGS iter 109: f=0.00144338
BFGS iter 110: f=0.00144284
BFGS iter 111: f=0.00144224
BFGS iter 112: f=0.00144163
BFGS iter 113: f=0.00144103
BFGS iter 114: f=0.00144034
BFGS iter 115: f=0.00143964
BFGS iter 116: f=0.00143925
BFGS iter 117: f=0.00143918
BFGS iter 118: f=0.00143913
BFGS iter 119: f=0.00143905
BFGS iter 120: f=0.00143867
BFGS iter 121: f=0.00143802
BFGS iter 122: f=0.00143771
BFGS iter 123: f=0.00143754
BFGS iter 124: f=0.00143744
BFGS iter 125: f=0.00143738
BFGS iter 126: f=0.00143734
BFGS iter 127: f=0.0014372
BFGS iter 128: f=0.00143691
BFGS iter 129: f=0.00143679
BFGS iter 130: f=0.00143666
BFGS iter 131: f=0.00143629
BFGS iter 132: f=0.00143265
BFGS iter 133: f=0.00143072
BFGS iter 134: f=0.00142931
BFGS iter 135: f=0.00142869
BFGS iter 136: f=0.00142838
BFGS iter 137: f=0.00142826
BFGS iter 138: f=0.00142817
BFGS iter 139: f=0.00142813
BFGS iter 140: f=0.00142809
BFGS iter 141: f=0.00142798
BFGS iter 142: f=0.00142784
BFGS iter 143: f=0.00142753
BFGS iter 144: f=0.00142722
BFGS iter 145: f=0.00142716
BFGS iter 146: f=0.00142711
BFGS iter 147: f=0.00142696
BFGS iter 148: f=0.00142666
BFGS iter 149: f=0.00142639
BFGS iter 150: f=0.00141472
BFGS iter 151: f=0.00141445
BFGS iter 152: f=0.00141389
BFGS iter 153: f=0.0014126
BFGS iter 154: f=0.00141239
BFGS iter 155: f=0.00141215
BFGS iter 156: f=0.00141163
BFGS iter 157: f=0.00141055
BFGS iter 158: f=0.00141026
BFGS iter 159: f=0.00141017
BFGS iter 160: f=0.0014101
BFGS iter 161: f=0.00141004
BFGS iter 162: f=0.00140999
BFGS iter 163: f=0.00140993
BFGS iter 164: f=0.0014098
BFGS iter 165: f=0.00140954
BFGS iter 166: f=0.00140924
BFGS iter 167: f=0.00140896
BFGS iter 168: f=0.00140889
BFGS iter 169: f=0.00140879
BFGS iter 170: f=0.00140867
BFGS iter 171: f=0.00140839
BFGS iter 172: f=0.00140766
BFGS iter 173: f=0.00140683
BFGS iter 174: f=0.00140615
BFGS iter 175: f=0.0014058
BFGS iter 176: f=0.00140552
BFGS iter 177: f=0.00140541
BFGS iter 178: f=0.00140532
BFGS iter 179: f=0.00140528
BFGS iter 180: f=0.00140524
BFGS iter 181: f=0.00140519
BFGS iter 182: f=0.00140512
BFGS iter 183: f=0.00140509
BFGS iter 184: f=0.00140507
BFGS iter 185: f=0.00140505
BFGS iter 186: f=0.00140504
BFGS iter 187: f=0.00140502
BFGS iter 188: f=0.00140498
BFGS iter 189: f=0.00140483
BFGS iter 190: f=0.00140401
BFGS iter 191: f=0.00140226
BFGS iter 192: f=0.00140016
BFGS iter 193: f=0.00139933
BFGS iter 194: f=0.00139803
BFGS iter 195: f=0.00139719
BFGS iter 196: f=0.00139677
BFGS iter 197: f=0.00139638
BFGS iter 198: f=0.00139614
BFGS iter 199: f=0.00139598
BFGS iter 200: f=0.00139118
BFGS iter 201: f=0.00139106
BFGS iter 202: f=0.00139099
BFGS iter 203: f=0.00139086
BFGS iter 204: f=0.00139043
BFGS iter 205: f=0.00139005
BFGS iter 206: f=0.0013896
BFGS iter 207: f=0.00138914
BFGS iter 208: f=0.00138892
BFGS iter 209: f=0.00138878
BFGS iter 210: f=0.00138869
BFGS iter 211: f=0.00138855
BFGS iter 212: f=0.00138828
BFGS iter 213: f=0.00138768
BFGS iter 214: f=0.00138735
BFGS iter 215: f=0.00138687
BFGS iter 216: f=0.00138622
BFGS iter 217: f=0.00138614
BFGS iter 218: f=0.00138609
BFGS iter 219: f=0.00138601
BFGS iter 220: f=0.00138587
BFGS iter 221: f=0.00138576
BFGS iter 222: f=0.00138546
BFGS iter 223: f=0.00138485
BFGS iter 224: f=0.00138388
BFGS iter 225: f=0.00138294
BFGS iter 226: f=0.00138255
BFGS iter 227: f=0.00138174
BFGS iter 228: f=0.00138083
BFGS iter 229: f=0.0013802
BFGS iter 230: f=0.00137921
BFGS iter 231: f=0.00137705
BFGS iter 232: f=0.00137354
BFGS iter 233: f=0.001372
BFGS iter 234: f=0.00136923
BFGS iter 235: f=0.00136676
BFGS iter 236: f=0.00136583
BFGS iter 237: f=0.00136524
BFGS iter 238: f=0.00136468
BFGS iter 239: f=0.0013642
BFGS iter 240: f=0.00136377
BFGS iter 241: f=0.00136316
BFGS iter 242: f=0.00136211
BFGS iter 243: f=0.00136024
BFGS iter 244: f=0.00135615
BFGS iter 245: f=0.00135231
BFGS iter 246: f=0.00134952
BFGS iter 247: f=0.00134893
BFGS iter 248: f=0.00134884
BFGS iter 249: f=0.00134883
BFGS iter 250: f=0.00133833
BFGS iter 251: f=0.00133827
BFGS iter 252: f=0.00133742
BFGS iter 253: f=0.00133735
BFGS iter 254: f=0.00133707
BFGS iter 255: f=0.00133694
BFGS iter 256: f=0.00133681
BFGS iter 257: f=0.00133667
BFGS iter 258: f=0.00133634
BFGS iter 259: f=0.00133526
BFGS iter 260: f=0.00133484
BFGS iter 261: f=0.00133458
BFGS iter 262: f=0.00133431
BFGS iter 263: f=0.00133405
BFGS iter 264: f=0.00133384
BFGS iter 265: f=0.00133366
BFGS iter 266: f=0.00133358
BFGS iter 267: f=0.00133353
BFGS iter 268: f=0.00133331
BFGS iter 269: f=0.00133308
BFGS iter 270: f=0.00133252
BFGS iter 271: f=0.00133133
BFGS iter 272: f=0.00133052
BFGS iter 273: f=0.00133021
BFGS iter 274: f=0.00133
BFGS iter 275: f=0.00132977
BFGS iter 276: f=0.00132958
BFGS iter 277: f=0.00132945
BFGS iter 278: f=0.00132924
BFGS iter 279: f=0.00132876
BFGS iter 280: f=0.00132852
BFGS iter 281: f=0.00132834
BFGS iter 282: f=0.0013281
BFGS iter 283: f=0.00132779
BFGS iter 284: f=0.00132768
BFGS iter 285: f=0.00132764
BFGS iter 286: f=0.00132757
BFGS iter 287: f=0.0013274
BFGS iter 288: f=0.00132706
BFGS iter 289: f=0.00132339
BFGS iter 290: f=0.0013218
BFGS iter 291: f=0.00132017
BFGS iter 292: f=0.00131909
BFGS iter 293: f=0.00131875
BFGS iter 294: f=0.00131835
BFGS iter 295: f=0.00131802
BFGS iter 296: f=0.00131771
BFGS iter 297: f=0.00131741
BFGS iter 298: f=0.00131712
BFGS iter 299: f=0.0013165
*
BFGS iter 300: f=0.00131774
BFGS iter 301: f=0.00131752
BFGS iter 302: f=0.00131639
BFGS iter 303: f=0.00131575
BFGS iter 304: f=0.00131553
BFGS iter 305: f=0.00131539
BFGS iter 306: f=0.00131529
BFGS iter 307: f=0.00131517
BFGS iter 308: f=0.001315
BFGS iter 309: f=0.00131473
BFGS iter 310: f=0.00131443
BFGS iter 311: f=0.00131383
BFGS iter 312: f=0.00131333
BFGS iter 313: f=0.0013127
BFGS iter 314: f=0.00131243
BFGS iter 315: f=0.00131226
BFGS iter 316: f=0.00131219
BFGS iter 317: f=0.00131211
BFGS iter 318: f=0.00131194
BFGS iter 319: f=0.00131184
BFGS iter 320: f=0.0013116
BFGS iter 321: f=0.00131111
BFGS iter 322: f=0.00131089
BFGS iter 323: f=0.00131072
BFGS iter 324: f=0.00131067
BFGS iter 325: f=0.00131064
BFGS iter 326: f=0.0013106
BFGS iter 327: f=0.00131049
BFGS iter 328: f=0.00131039
BFGS iter 329: f=0.00131028
BFGS iter 330: f=0.0013102
BFGS iter 331: f=0.00131019
BFGS iter 332: f=0.00131015
BFGS iter 333: f=0.0013101
BFGS iter 334: f=0.00131008
BFGS iter 335: f=0.00131005
BFGS iter 336: f=0.00131001
BFGS iter 337: f=0.00130999
BFGS iter 338: f=0.00130995
BFGS iter 339: f=0.00130985
BFGS iter 340: f=0.00130979
BFGS iter 341: f=0.00130965
BFGS iter 342: f=0.00130955
BFGS iter 343: f=0.0013094
BFGS iter 344: f=0.00130932
BFGS iter 345: f=0.0013092
BFGS iter 346: f=0.0013091
BFGS iter 347: f=0.00130893
BFGS iter 348: f=0.00130862
BFGS iter 349: f=0.00130802
BFGS iter 350: f=0.00130032
BFGS iter 351: f=0.00129869
BFGS iter 352: f=0.00129732
BFGS iter 353: f=0.00129662
BFGS iter 354: f=0.00129614
BFGS iter 355: f=0.00129595
BFGS iter 356: f=0.00129556
BFGS iter 357: f=0.00129534
BFGS iter 358: f=0.00129513
BFGS iter 359: f=0.00129502
BFGS iter 360: f=0.00129491
BFGS iter 361: f=0.00129488
BFGS iter 362: f=0.00129486
BFGS iter 363: f=0.00129485
BFGS iter 364: f=0.00129484
BFGS iter 365: f=0.00129482
BFGS iter 366: f=0.0012948
BFGS iter 367: f=0.00129479
BFGS iter 368: f=0.00129477
BFGS iter 369: f=0.00129474
BFGS iter 370: f=0.00129458
BFGS iter 371: f=0.00129436
BFGS iter 372: f=0.00129422
BFGS iter 373: f=0.00129419
BFGS iter 374: f=0.00129416
BFGS iter 375: f=0.00129413
BFGS iter 376: f=0.00129412
BFGS iter 377: f=0.00129412
BFGS iter 378: f=0.00129412
BFGS iter 379: f=0.00129412
BFGS iter 380: f=0.00129412
BFGS iter 381: f=0.00129412
BFGS iter 382: f=0.00129412
BFGS iter 383: f=0.00129411
BFGS iter 384: f=0.00129408
BFGS iter 385: f=0.00129373
BFGS iter 386: f=0.00129331
BFGS iter 387: f=0.00129326
BFGS iter 388: f=0.00129318
BFGS iter 389: f=0.00129316
BFGS iter 390: f=0.00129314
BFGS iter 391: f=0.00129312
BFGS iter 392: f=0.0012931
BFGS iter 393: f=0.00129309
BFGS iter 394: f=0.00129309
BFGS iter 395: f=0.00129309
BFGS iter 396: f=0.00129309
BFGS iter 397: f=0.00129309
BFGS iter 398: f=0.00129309
BFGS iter 399: f=0.00129309
BFGS iter 400: f=0.00128802
BFGS iter 401: f=0.00128704
BFGS iter 402: f=0.00128619
BFGS iter 403: f=0.00128595
BFGS iter 404: f=0.00128579
BFGS iter 405: f=0.00128568
BFGS iter 406: f=0.00128558
BFGS iter 407: f=0.00128549
BFGS iter 408: f=0.00128544
BFGS iter 409: f=0.00128531
BFGS iter 410: f=0.00128514
BFGS iter 411: f=0.00128502
BFGS iter 412: f=0.00128491
BFGS iter 413: f=0.00128484
BFGS iter 414: f=0.0012848
BFGS iter 415: f=0.00128476
BFGS iter 416: f=0.00128472
BFGS iter 417: f=0.0012847
BFGS iter 418: f=0.00128468
BFGS iter 419: f=0.00128466
BFGS iter 420: f=0.00128465
BFGS iter 421: f=0.00128463
BFGS iter 422: f=0.00128461
BFGS iter 423: f=0.00128458
BFGS iter 424: f=0.0012845
BFGS iter 425: f=0.00128438
BFGS iter 426: f=0.0012842
BFGS iter 427: f=0.00128409
BFGS iter 428: f=0.00128371
BFGS iter 429: f=0.00128355
BFGS iter 430: f=0.00128325
BFGS iter 431: f=0.00128314
BFGS iter 432: f=0.00128307
BFGS iter 433: f=0.00128304
BFGS iter 434: f=0.00128302
BFGS iter 435: f=0.00128302
BFGS iter 436: f=0.00128302
BFGS iter 437: f=0.00128302
BFGS iter 438: f=0.00128302
BFGS iter 439: f=0.00128301
BFGS iter 440: f=0.001283
BFGS iter 441: f=0.00128297
BFGS iter 442: f=0.00128295
BFGS iter 443: f=0.00128293
BFGS iter 444: f=0.00128292
BFGS iter 445: f=0.0012829
BFGS iter 446: f=0.00128288
BFGS iter 447: f=0.00128287
BFGS iter 448: f=0.00128287
BFGS iter 449: f=0.00128286
BFGS iter 450: f=0.00127911
BFGS iter 451: f=0.00127839
BFGS iter 452: f=0.00127804
BFGS iter 453: f=0.00127772
BFGS iter 454: f=0.00127734
BFGS iter 455: f=0.00127716
BFGS iter 456: f=0.0012771
BFGS iter 457: f=0.00127705
BFGS iter 458: f=0.00127703
BFGS iter 459: f=0.00127701
BFGS iter 460: f=0.00127698
BFGS iter 461: f=0.00127697
BFGS iter 462: f=0.00127696
BFGS iter 463: f=0.00127696
BFGS iter 464: f=0.00127695
BFGS iter 465: f=0.00127695
BFGS iter 466: f=0.00127695
BFGS iter 467: f=0.00127695
BFGS iter 468: f=0.00127694
BFGS iter 469: f=0.00127694
BFGS iter 470: f=0.00127694
BFGS iter 471: f=0.00127694
BFGS iter 472: f=0.00127694
BFGS iter 473: f=0.00127694
BFGS iter 474: f=0.00127693
BFGS iter 475: f=0.0012769
BFGS iter 476: f=0.00127682
BFGS iter 477: f=0.00127677
BFGS iter 478: f=0.00127669
BFGS iter 479: f=0.00127662
BFGS iter 480: f=0.0012766
BFGS iter 481: f=0.00127658
BFGS iter 482: f=0.00127654
BFGS iter 483: f=0.0012765
BFGS iter 484: f=0.00127648
BFGS iter 485: f=0.00127643
BFGS iter 486: f=0.0012764
BFGS iter 487: f=0.00127637
BFGS iter 488: f=0.00127634
BFGS iter 489: f=0.00127633
BFGS iter 490: f=0.00127631
BFGS iter 491: f=0.00127629
BFGS iter 492: f=0.00127624
BFGS iter 493: f=0.00127623
BFGS iter 494: f=0.00127619
BFGS iter 495: f=0.00127617
BFGS iter 496: f=0.00127615
BFGS iter 497: f=0.00127612
BFGS iter 498: f=0.0012761
BFGS iter 499: f=0.00127607
BFGS iter 500: f=0.00127358
BFGS iter 501: f=0.00127323
BFGS iter 502: f=0.00127285
BFGS iter 503: f=0.00127268
BFGS iter 504: f=0.00127262
BFGS iter 505: f=0.00127254
BFGS iter 506: f=0.0012725
BFGS iter 507: f=0.00127247
BFGS iter 508: f=0.00127245
BFGS iter 509: f=0.00127243
BFGS iter 510: f=0.00127242
BFGS iter 511: f=0.0012724
BFGS iter 512: f=0.00127239
BFGS iter 513: f=0.00127237
BFGS iter 514: f=0.00127235
BFGS iter 515: f=0.00127231
BFGS iter 516: f=0.00127229
BFGS iter 517: f=0.00127226
BFGS iter 518: f=0.00127221
BFGS iter 519: f=0.00127217
BFGS iter 520: f=0.00127215
BFGS iter 521: f=0.00127213
BFGS iter 522: f=0.00127211
BFGS iter 523: f=0.0012721
BFGS iter 524: f=0.00127209
BFGS iter 525: f=0.00127208
BFGS iter 526: f=0.00127205
BFGS iter 527: f=0.00127199
BFGS iter 528: f=0.00127195
BFGS iter 529: f=0.00127189
BFGS iter 530: f=0.00127184
BFGS iter 531: f=0.00127172
BFGS iter 532: f=0.00127167
BFGS iter 533: f=0.00127165
BFGS iter 534: f=0.00127164
BFGS iter 535: f=0.00127164
BFGS iter 536: f=0.00127164
BFGS iter 537: f=0.00127164
BFGS iter 538: f=0.00127164
BFGS iter 539: f=0.00127164
BFGS iter 540: f=0.00127164
BFGS iter 541: f=0.00127164
BFGS iter 542: f=0.00127164
BFGS iter 543: f=0.00127164
BFGS iter 544: f=0.00127164
BFGS iter 545: f=0.00127164
BFGS iter 546: f=0.00127164
BFGS iter 547: f=0.0012716
BFGS iter 548: f=0.00127154
BFGS iter 549: f=0.00127152
BFGS iter 550: f=0.00126908
BFGS iter 551: f=0.0012689
BFGS iter 552: f=0.0012688
BFGS iter 553: f=0.00126868
BFGS iter 554: f=0.00126866
BFGS iter 555: f=0.00126865
BFGS iter 556: f=0.00126863
BFGS iter 557: f=0.00126862
BFGS iter 558: f=0.00126862
BFGS iter 559: f=0.00126862
BFGS iter 560: f=0.00126861
BFGS iter 561: f=0.0012686
BFGS iter 562: f=0.00126857
BFGS iter 563: f=0.00126855
BFGS iter 564: f=0.00126849
BFGS iter 565: f=0.00126846
BFGS iter 566: f=0.00126845
BFGS iter 567: f=0.00126844
BFGS iter 568: f=0.00126842
BFGS iter 569: f=0.00126841
BFGS iter 570: f=0.00126841
BFGS iter 571: f=0.0012684
BFGS iter 572: f=0.0012684
BFGS iter 573: f=0.00126839
BFGS iter 574: f=0.00126838
BFGS iter 575: f=0.00126837
BFGS iter 576: f=0.00126835
BFGS iter 577: f=0.00126833
BFGS iter 578: f=0.00126831
BFGS iter 579: f=0.0012683
BFGS iter 580: f=0.00126829
BFGS iter 581: f=0.00126828
BFGS iter 582: f=0.00126827
BFGS iter 583: f=0.00126826
BFGS iter 584: f=0.00126826
BFGS iter 585: f=0.00126825
BFGS iter 586: f=0.00126825
BFGS iter 587: f=0.00126825
BFGS iter 588: f=0.00126825
BFGS iter 589: f=0.00126825
BFGS iter 590: f=0.00126824
BFGS iter 591: f=0.00126824
BFGS iter 592: f=0.00126824
BFGS iter 593: f=0.00126824
BFGS iter 594: f=0.00126824
BFGS iter 595: f=0.00126824
BFGS iter 596: f=0.00126824
BFGS iter 597: f=0.00126824
BFGS iter 598: f=0.00126824
BFGS iter 599: f=0.00126824
BFGS ended due to small decr. in 50 iterations
MTPR training ended
Rescaling...
   scaling = 0.0164672053690586, condition number = 70.6156671857343
   scaling = 0.017964224038973, condition number = 75.3618633759153
   scaling = 0.0197606464428703, condition number = 75.663953032708
   scaling = 0.0217367110871574, condition number = 72.4468729002075
   scaling = 0.0237127757314444, condition number = 68.4581733817766
Rescaling to 0.0237127757314444... done
Rescaling...
   scaling = 0.0197606464428703, condition number = 75.6639545526395
   scaling = 0.0215570688467676, condition number = 73.2000236635552
   scaling = 0.0237127757314444, condition number = 68.4581733817766
   scaling = 0.0260840533045889, condition number = 61.3320050784218
   scaling = 0.0284553308777333, condition number = 56.5134663411057
Rescaling to 0.0284553308777333... done
Rescaling...
   scaling = 0.0237127757314444, condition number = 68.4581733817766
   scaling = 0.0258684826161212, condition number = 61.9767018939825
   scaling = 0.0284553308777333, condition number = 56.5134663411057
   scaling = 0.0313008639655066, condition number = 57.4275858840171
   scaling = 0.03414639705328, condition number = 56.3872608582728
Rescaling to 0.03414639705328... done
Rescaling...
   scaling = 0.0284553308777333, condition number = 56.5071997670009
   scaling = 0.0310421791393454, condition number = 57.3964403521379
   scaling = 0.03414639705328, condition number = 56.3872608582728
   scaling = 0.037561036758608, condition number = 54.4388382642689
   scaling = 0.0409756764639359, condition number = 52.4384006244198
Rescaling to 0.0409756764639359... done
Rescaling...
   scaling = 0.03414639705328, condition number = 56.3872608582728
   scaling = 0.0372506149672145, condition number = 54.5505562693927
   scaling = 0.0409756764639359, condition number = 52.4384006244198
   scaling = 0.0450732441103295, condition number = 50.1269066816452
   scaling = 0.0491708117567231, condition number = 48.3101279017314
Rescaling to 0.0491708117567231... done
Rescaling...
   scaling = 0.0409756764639359, condition number = 52.4384006244198
   scaling = 0.0447007379606574, condition number = 50.4305680711754
   scaling = 0.0491708117567231, condition number = 48.3101279017314
   scaling = 0.0540878929323955, condition number = 46.8314189087074
   scaling = 0.0590049741080678, condition number = 45.6378288977277
Rescaling to 0.0590049741080678... done
Rescaling...
   scaling = 0.0491708117567231, condition number = 48.3101279017314
   scaling = 0.0536408855527889, condition number = 47.0538991895777
   scaling = 0.0590049741080678, condition number = 45.6378288977277
   scaling = 0.0649054715188745, condition number = 44.6578297755793
   scaling = 0.0708059689296813, condition number = 37.6000098117601
Rescaling to 0.0708059689296813... done
Rescaling...
   scaling = 0.0590049741080678, condition number = 45.6378288977277
   scaling = 0.0643690626633466, condition number = 45.0570298742572
   scaling = 0.0708059689296813, condition number = 37.6000098117601
   scaling = 0.0778865658226494, condition number = 37.5466670622965
   scaling = 0.0849671627156176, condition number = 37.6656810684507
Rescaling to 0.0778865658226494... done
Rescaling...
   scaling = 0.0649054715188745, condition number = 44.6578292810224
   scaling = 0.0708059689296813, condition number = 37.6000105662553
   scaling = 0.0778865658226494, condition number = 37.5466698688098
   scaling = 0.0856752224049144, condition number = 37.8727394540415
   scaling = 0.0934638789871793, condition number = 38.2571809965985
Rescaling to 0.0778865658226494... done

		* * * TRAIN ERRORS * * *

_________________Errors report_________________
Energy:
	Errors checked for 100 configurations
	Maximal absolute difference = 0.0225331
	Average absolute difference = 0.00915164
	RMS     absolute difference = 0.010589

Energy per atom:
	Errors checked for 100 configurations
	Maximal absolute difference = 0.00070416
	Average absolute difference = 0.000285989
	RMS     absolute difference = 0.000330907

Forces:
	Errors checked for 3200 atoms
	Maximal absolute difference = 0.162349
	Average absolute difference = 0.0180399
	RMS     absolute difference = 0.0342944
	Max(ForceDiff) / Max(Force) = 0.103983
	RMS(ForceDiff) / RMS(Force) = 0.0961624

Stresses (in eV):
	Errors checked for 100 configurations
	Maximal absolute difference = 3.28732
	Average absolute difference = 0.200669
	RMS     absolute difference = 0.657612
	Max(StresDiff) / Max(Stres) = 0.257521
	RMS(StresDiff) / RMS(Stres) = 0.177097

Stresses (in GPa):
	Errors checked for 100 configurations
	Maximal absolute difference = 0.998284
	Average absolute difference = 0.0609385
	RMS     absolute difference = 0.199701
	Max(StresDiff) / Max(Stres) = 0.257521
	RMS(StresDiff) / RMS(Stres) = 0.177097
_______________________________________________

