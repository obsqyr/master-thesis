MTPR from untrained_mtps/06.mtp, Database: cfg_train/Al_train_100.cfg
validation set: cfg_test/Al_test_1000.cfg
Random initialization of radial coefficients
Rescaling...
   scaling = 0.833333333333333, condition number = 685.092567923678
   scaling = 0.909090909090909, condition number = 815.314338335741
   scaling = 1, condition number = 986.527066092671
   scaling = 1.1, condition number = 1193.69453892286
   scaling = 1.2, condition number = 1420.59229854402
Rescaling to 0.833333333333333... done
Rescaling...
   scaling = 0.694444444444445, condition number = 475.764233352628
   scaling = 0.757575757575758, condition number = 566.195499081097
   scaling = 0.833333333333333, condition number = 685.093081827151
   scaling = 0.916666666666667, condition number = 828.959265149751
   scaling = 1, condition number = 986.527066092671
Rescaling to 0.694444444444445... done
Rescaling...
   scaling = 0.578703703703704, condition number = 330.397445178201
   scaling = 0.631313131313131, condition number = 393.196687073268
   scaling = 0.694444444444445, condition number = 475.764233352628
   scaling = 0.763888888888889, condition number = 575.671128816666
   scaling = 0.833333333333333, condition number = 685.093081827151
Rescaling to 0.578703703703704... done
Rescaling...
   scaling = 0.482253086419753, condition number = 229.449012528145
   scaling = 0.526094276094276, condition number = 273.05921007542
   scaling = 0.578703703703704, condition number = 330.397445178201
   scaling = 0.636574074074074, condition number = 399.776964387505
   scaling = 0.694444444444445, condition number = 475.764233352628
Rescaling to 0.482253086419753... done
Rescaling...
   scaling = 0.401877572016461, condition number = 159.347087885379
   scaling = 0.43841189674523, condition number = 189.631328315381
   scaling = 0.482253086419753, condition number = 229.449012528145
   scaling = 0.530478395061729, condition number = 277.628814375536
   scaling = 0.578703703703704, condition number = 330.397445178201
Rescaling to 0.401877572016461... done
Rescaling...
   scaling = 0.334897976680384, condition number = 110.667081725392
   scaling = 0.365343247287692, condition number = 131.696785319809
   scaling = 0.401877572016461, condition number = 159.347087885379
   scaling = 0.442065329218107, condition number = 192.804612677732
   scaling = 0.482253086419753, condition number = 229.449012528062
Rescaling to 0.334897976680384... done
Rescaling...
   scaling = 0.279081647233653, condition number = 76.8647034574693
   scaling = 0.304452706073077, condition number = 91.4669326405932
   scaling = 0.334897976680384, condition number = 110.667081725392
   scaling = 0.368387774348423, condition number = 133.900370188603
   scaling = 0.401877572016461, condition number = 159.347087885379
Rescaling to 0.279081647233653... done
Rescaling...
   scaling = 0.232568039361378, condition number = 53.3963757575037
   scaling = 0.25371058839423, condition number = 63.5337716818648
   scaling = 0.279081647233653, condition number = 76.8647034574693
   scaling = 0.306989811957019, condition number = 92.9970570200334
   scaling = 0.334897976680384, condition number = 110.667081725392
Rescaling to 0.232568039361378... done
Rescaling...
   scaling = 0.193806699467815, condition number = 36.8332653233859
   scaling = 0.211425490328525, condition number = 40.5052226189268
   scaling = 0.232568039361378, condition number = 53.3963757575037
   scaling = 0.255824843297516, condition number = 64.5961093323929
   scaling = 0.279081647233653, condition number = 76.8647034574693
Rescaling to 0.193806699467815... done
Rescaling...
   scaling = 0.161505582889846, condition number = 25.8166495685161
   scaling = 0.176187908607104, condition number = 30.6913480920139
   scaling = 0.193806699467815, condition number = 36.8332653233859
   scaling = 0.213187369414596, condition number = 41.5249283326965
   scaling = 0.232568039361378, condition number = 53.3963757575037
Rescaling to 0.161505582889846... done
Rescaling...
   scaling = 0.134587985741538, condition number = 18.0098223347324
   scaling = 0.146823257172587, condition number = 21.3755004833297
   scaling = 0.161505582889846, condition number = 25.8166495685161
   scaling = 0.17765614117883, condition number = 31.2025263591958
   scaling = 0.193806699467815, condition number = 36.8332653233875
Rescaling to 0.134587985741538... done
Rescaling...
   scaling = 0.112156654784615, condition number = 12.6556226283295
   scaling = 0.122352714310489, condition number = 14.9553630202974
   scaling = 0.134587985741538, condition number = 18.0098223347324
   scaling = 0.148046784315692, condition number = 21.7289198051455
   scaling = 0.161505582889846, condition number = 25.8166495685161
Rescaling to 0.112156654784615... done
Rescaling...
   scaling = 0.0934638789871793, condition number = 9.06573088111919
   scaling = 0.101960595258741, condition number = 10.5913995119737
   scaling = 0.112156654784615, condition number = 12.6556226283295
   scaling = 0.123372320263077, condition number = 15.1977874427086
   scaling = 0.134587985741538, condition number = 18.0098223347324
Rescaling to 0.0934638789871793... done
Rescaling...
   scaling = 0.0778865658226494, condition number = 6.80728755884809
   scaling = 0.0849671627156175, condition number = 7.73833931391452
   scaling = 0.0934638789871793, condition number = 9.06573088111919
   scaling = 0.102810266885897, condition number = 10.7539981676492
   scaling = 0.112156654784615, condition number = 12.6556226283295
Rescaling to 0.0778865658226494... done
Rescaling...
   scaling = 0.0649054715188745, condition number = 5.62112264742486
   scaling = 0.0708059689296813, condition number = 6.06596113036926
   scaling = 0.0778865658226494, condition number = 6.80728755884809
   scaling = 0.0856752224049144, condition number = 7.84067323147991
   scaling = 0.0934638789871793, condition number = 9.0657308811189
Rescaling to 0.0649054715188745... done
Rescaling...
   scaling = 0.0540878929323954, condition number = 5.30706997712241
   scaling = 0.0590049741080677, condition number = 5.3618007691561
   scaling = 0.0649054715188745, condition number = 5.62112264742486
   scaling = 0.071396018670762, condition number = 6.11959812484179
   scaling = 0.0778865658226494, condition number = 6.80728755884718
Rescaling to 0.0540878929323954... done
Rescaling...
   scaling = 0.0450732441103295, condition number = 5.64032901425281
   scaling = 0.0491708117567231, condition number = 5.41497828266863
   scaling = 0.0540878929323954, condition number = 5.30706997712241
   scaling = 0.059496682225635, condition number = 5.37565270302041
   scaling = 0.0649054715188745, condition number = 5.62112264742486
Rescaling to 0.0540878929323954... done
Pre-training started
MTPR parallel training started
BFGS iter 0: f=0.0861659
BFGS iter 1: f=0.0771262
BFGS iter 2: f=0.0667495
BFGS iter 3: f=0.0575754
BFGS iter 4: f=0.0397751
BFGS iter 5: f=0.0267506
BFGS iter 6: f=0.014822
BFGS iter 7: f=0.0124337
BFGS iter 8: f=0.0106775
BFGS iter 9: f=0.00836576
BFGS iter 10: f=0.00707205
BFGS iter 11: f=0.00629072
BFGS iter 12: f=0.0052227
BFGS iter 13: f=0.0050003
BFGS iter 14: f=0.00487831
BFGS iter 15: f=0.0043372
BFGS iter 16: f=0.00398516
BFGS iter 17: f=0.00367343
BFGS iter 18: f=0.00354962
BFGS iter 19: f=0.00347262
BFGS iter 20: f=0.0033946
BFGS iter 21: f=0.00335613
BFGS iter 22: f=0.0033403
BFGS iter 23: f=0.00332865
BFGS iter 24: f=0.00330748
BFGS iter 25: f=0.00327615
BFGS iter 26: f=0.00326393
BFGS iter 27: f=0.00325751
BFGS iter 28: f=0.00325598
BFGS iter 29: f=0.00325285
BFGS iter 30: f=0.00324082
BFGS iter 31: f=0.00323411
BFGS iter 32: f=0.00323234
BFGS iter 33: f=0.00323159
BFGS iter 34: f=0.00322684
BFGS iter 35: f=0.00321307
BFGS iter 36: f=0.00320531
BFGS iter 37: f=0.00320207
BFGS iter 38: f=0.00320105
BFGS iter 39: f=0.00319734
BFGS iter 40: f=0.00317659
BFGS iter 41: f=0.00314255
BFGS iter 42: f=0.00311828
BFGS iter 43: f=0.00309653
BFGS iter 44: f=0.003089
BFGS iter 45: f=0.00308353
BFGS iter 46: f=0.00307233
BFGS iter 47: f=0.00306729
BFGS iter 48: f=0.00306232
BFGS iter 49: f=0.00305864
BFGS iter 50: f=0.00300571
BFGS iter 51: f=0.00298738
BFGS iter 52: f=0.00297613
BFGS iter 53: f=0.00297278
BFGS iter 54: f=0.00296953
BFGS iter 55: f=0.00296557
BFGS iter 56: f=0.00295182
BFGS iter 57: f=0.00293665
BFGS iter 58: f=0.00292975
BFGS iter 59: f=0.00292717
BFGS iter 60: f=0.00292648
BFGS iter 61: f=0.00292559
BFGS iter 62: f=0.00292507
BFGS iter 63: f=0.00292477
BFGS iter 64: f=0.00292459
BFGS iter 65: f=0.00292449
BFGS iter 66: f=0.00292441
BFGS iter 67: f=0.00292427
BFGS iter 68: f=0.00292322
BFGS iter 69: f=0.00291886
BFGS iter 70: f=0.00290967
BFGS iter 71: f=0.00290353
BFGS iter 72: f=0.00289229
BFGS iter 73: f=0.00288386
BFGS iter 74: f=0.00287754
step limit reached
MTPR training ended
Rescaling...
   scaling = 0.0450732441103295, condition number = 6.52193677254174
   scaling = 0.0491708117567231, condition number = 5.08780967793808
   scaling = 0.0540878929323954, condition number = 4.18623581122601
   scaling = 0.059496682225635, condition number = 3.92792503920931
   scaling = 0.0649054715188745, condition number = 3.75926368725397
Rescaling to 0.0649054715188745... done
Rescaling...
   scaling = 0.0540878929323954, condition number = 4.18623581122601
   scaling = 0.0590049741080677, condition number = 3.94754070647013
   scaling = 0.0649054715188745, condition number = 3.75926368725397
   scaling = 0.071396018670762, condition number = 3.66313086998787
   scaling = 0.0778865658226494, condition number = 3.67306865054178
Rescaling to 0.071396018670762... done
Rescaling...
   scaling = 0.059496682225635, condition number = 3.92792503920931
   scaling = 0.0649054715188745, condition number = 3.75926368725397
   scaling = 0.071396018670762, condition number = 3.66313086998787
   scaling = 0.0785356205378382, condition number = 3.67954032733386
   scaling = 0.0856752224049144, condition number = 3.81196429084971
Rescaling to 0.071396018670762... done
Pre-training ended
BFGS iterations count set to 1000
BFGS convergence tolerance set to 0.001
Energy weight: 1
Force weight: 0.01
Stress weight: 0.001
MTPR parallel training started
BFGS iter 0: f=0.0028573
BFGS iter 1: f=0.0028572
BFGS iter 2: f=0.00285698
BFGS iter 3: f=0.00285644
BFGS iter 4: f=0.00285173
BFGS iter 5: f=0.00284936
BFGS iter 6: f=0.00284652
BFGS iter 7: f=0.00284417
BFGS iter 8: f=0.00284164
BFGS iter 9: f=0.00283692
BFGS iter 10: f=0.0028297
BFGS iter 11: f=0.00281468
BFGS iter 12: f=0.00280798
BFGS iter 13: f=0.00280639
BFGS iter 14: f=0.00280559
BFGS iter 15: f=0.00280414
BFGS iter 16: f=0.00280263
BFGS iter 17: f=0.00280211
BFGS iter 18: f=0.00280103
BFGS iter 19: f=0.00279871
BFGS iter 20: f=0.00279702
BFGS iter 21: f=0.00279597
BFGS iter 22: f=0.00279504
BFGS iter 23: f=0.00279417
BFGS iter 24: f=0.00279359
BFGS iter 25: f=0.00279324
BFGS iter 26: f=0.00279276
BFGS iter 27: f=0.00279202
BFGS iter 28: f=0.00279129
BFGS iter 29: f=0.00279108
BFGS iter 30: f=0.00279101
BFGS iter 31: f=0.00279084
BFGS iter 32: f=0.00278914
BFGS iter 33: f=0.00278555
BFGS iter 34: f=0.00278322
BFGS iter 35: f=0.00278091
BFGS iter 36: f=0.00277995
BFGS iter 37: f=0.0027793
BFGS iter 38: f=0.00277898
BFGS iter 39: f=0.00277892
BFGS iter 40: f=0.00277886
BFGS iter 41: f=0.00277868
BFGS iter 42: f=0.00277788
BFGS iter 43: f=0.00277576
BFGS iter 44: f=0.00277304
BFGS iter 45: f=0.00277048
BFGS iter 46: f=0.00276851
BFGS iter 47: f=0.00276673
BFGS iter 48: f=0.00276607
BFGS iter 49: f=0.00276549
BFGS iter 50: f=0.00275766
BFGS iter 51: f=0.002756
BFGS iter 52: f=0.00275524
BFGS iter 53: f=0.00275391
BFGS iter 54: f=0.00275286
BFGS iter 55: f=0.002752
BFGS iter 56: f=0.00275081
BFGS iter 57: f=0.00275015
BFGS iter 58: f=0.0027493
BFGS iter 59: f=0.00274882
BFGS iter 60: f=0.00274853
BFGS iter 61: f=0.00274807
BFGS iter 62: f=0.00274784
BFGS iter 63: f=0.00274763
BFGS iter 64: f=0.00274725
BFGS iter 65: f=0.00274711
BFGS iter 66: f=0.00274708
BFGS iter 67: f=0.00274698
BFGS iter 68: f=0.00274661
BFGS iter 69: f=0.00274653
BFGS iter 70: f=0.00274649
BFGS iter 71: f=0.00274637
BFGS iter 72: f=0.00274602
BFGS iter 73: f=0.0027457
BFGS iter 74: f=0.00274509
BFGS iter 75: f=0.0027431
BFGS iter 76: f=0.00274281
BFGS iter 77: f=0.00274251
BFGS iter 78: f=0.00274242
BFGS iter 79: f=0.00274234
BFGS iter 80: f=0.00274224
BFGS iter 81: f=0.00274213
BFGS iter 82: f=0.00274211
BFGS iter 83: f=0.00274209
BFGS iter 84: f=0.00274205
BFGS iter 85: f=0.00274176
BFGS iter 86: f=0.00274069
BFGS iter 87: f=0.00273971
BFGS iter 88: f=0.00273675
BFGS iter 89: f=0.00273201
BFGS iter 90: f=0.00272722
BFGS iter 91: f=0.00272439
BFGS iter 92: f=0.00272124
BFGS iter 93: f=0.00271721
BFGS iter 94: f=0.00271484
BFGS iter 95: f=0.00271229
BFGS iter 96: f=0.00271099
BFGS iter 97: f=0.00271005
BFGS iter 98: f=0.00270965
BFGS iter 99: f=0.00270949
BFGS iter 100: f=0.00268285
BFGS iter 101: f=0.00268188
BFGS iter 102: f=0.00268163
BFGS iter 103: f=0.00268011
BFGS iter 104: f=0.00267817
BFGS iter 105: f=0.00267335
BFGS iter 106: f=0.00267094
BFGS iter 107: f=0.00266842
BFGS iter 108: f=0.00266663
BFGS iter 109: f=0.00266528
BFGS iter 110: f=0.00266397
BFGS iter 111: f=0.00266319
BFGS iter 112: f=0.00266283
BFGS iter 113: f=0.00266249
BFGS iter 114: f=0.00266172
BFGS iter 115: f=0.00265972
BFGS iter 116: f=0.00265801
BFGS iter 117: f=0.00265695
BFGS iter 118: f=0.00265657
BFGS iter 119: f=0.00265643
BFGS iter 120: f=0.00265632
BFGS iter 121: f=0.00265615
BFGS iter 122: f=0.00265564
BFGS iter 123: f=0.00265385
BFGS iter 124: f=0.00265166
BFGS iter 125: f=0.00264891
BFGS iter 126: f=0.00264686
BFGS iter 127: f=0.00264476
BFGS iter 128: f=0.00264388
BFGS iter 129: f=0.0026434
BFGS iter 130: f=0.00264314
BFGS iter 131: f=0.00264287
BFGS iter 132: f=0.00264268
BFGS iter 133: f=0.00264259
BFGS iter 134: f=0.00264249
BFGS iter 135: f=0.00264243
BFGS iter 136: f=0.0026423
BFGS iter 137: f=0.00264215
BFGS iter 138: f=0.0026419
BFGS iter 139: f=0.00264112
BFGS iter 140: f=0.00263967
BFGS iter 141: f=0.00263865
BFGS iter 142: f=0.00263836
BFGS iter 143: f=0.00263827
BFGS iter 144: f=0.00263822
BFGS iter 145: f=0.00263818
BFGS iter 146: f=0.00263812
BFGS iter 147: f=0.00263804
BFGS iter 148: f=0.00263791
BFGS iter 149: f=0.0026377
BFGS iter 150: f=0.00263747
BFGS iter 151: f=0.00263739
BFGS iter 152: f=0.002637
BFGS iter 153: f=0.00263657
BFGS iter 154: f=0.00263652
BFGS iter 155: f=0.00263637
BFGS iter 156: f=0.00263595
BFGS iter 157: f=0.00263462
BFGS iter 158: f=0.00263287
BFGS iter 159: f=0.00263153
BFGS iter 160: f=0.00263121
BFGS iter 161: f=0.0026311
BFGS iter 162: f=0.00263085
BFGS iter 163: f=0.0026305
BFGS iter 164: f=0.0026304
BFGS iter 165: f=0.00263027
BFGS iter 166: f=0.00263009
BFGS iter 167: f=0.00263005
BFGS iter 168: f=0.00262999
BFGS iter 169: f=0.00262987
BFGS iter 170: f=0.00262981
BFGS iter 171: f=0.00262978
BFGS iter 172: f=0.00262963
BFGS iter 173: f=0.0026294
BFGS iter 174: f=0.00262894
BFGS iter 175: f=0.00262832
BFGS iter 176: f=0.00262784
BFGS iter 177: f=0.00262757
BFGS iter 178: f=0.00262735
BFGS iter 179: f=0.00262655
BFGS iter 180: f=0.0026253
BFGS iter 181: f=0.00262087
BFGS iter 182: f=0.00261821
BFGS iter 183: f=0.00261266
BFGS iter 184: f=0.00260608
BFGS iter 185: f=0.00259862
BFGS iter 186: f=0.00259375
BFGS iter 187: f=0.00259087
BFGS iter 188: f=0.00258843
BFGS iter 189: f=0.00258548
BFGS iter 190: f=0.0025846
BFGS iter 191: f=0.00258381
BFGS iter 192: f=0.00258257
BFGS iter 193: f=0.00258183
BFGS iter 194: f=0.00258148
BFGS iter 195: f=0.00258114
BFGS iter 196: f=0.00258086
BFGS iter 197: f=0.00258069
BFGS iter 198: f=0.00258043
BFGS iter 199: f=0.00258014
BFGS iter 200: f=0.00257336
BFGS iter 201: f=0.00257305
BFGS iter 202: f=0.00257296
BFGS iter 203: f=0.00257291
BFGS iter 204: f=0.00257287
BFGS iter 205: f=0.00257284
BFGS iter 206: f=0.00257283
BFGS iter 207: f=0.00257281
BFGS iter 208: f=0.0025728
BFGS iter 209: f=0.00257279
BFGS iter 210: f=0.00257279
BFGS iter 211: f=0.00257277
BFGS iter 212: f=0.00257273
BFGS iter 213: f=0.00257246
BFGS iter 214: f=0.00257229
BFGS iter 215: f=0.00257222
BFGS iter 216: f=0.00257221
BFGS iter 217: f=0.0025722
BFGS iter 218: f=0.00257219
BFGS iter 219: f=0.00257216
BFGS iter 220: f=0.00257209
BFGS iter 221: f=0.00257207
BFGS iter 222: f=0.00257206
BFGS iter 223: f=0.00257206
BFGS iter 224: f=0.00257206
BFGS iter 225: f=0.00257206
BFGS iter 226: f=0.00257206
BFGS iter 227: f=0.00257206
BFGS iter 228: f=0.00257193
BFGS iter 229: f=0.00257176
BFGS iter 230: f=0.00257166
BFGS iter 231: f=0.00257164
BFGS iter 232: f=0.00257164
BFGS iter 233: f=0.00257164
BFGS iter 234: f=0.00257164
BFGS iter 235: f=0.00257164
BFGS iter 236: f=0.00257164
BFGS ended due to small decr. for 1 iteration
BFGS iter 237: f=0.00257164
MTPR training ended
Rescaling...
   scaling = 0.059496682225635, condition number = 84.7464124285829
   scaling = 0.0649054715188745, condition number = 77.7405997990456
   scaling = 0.071396018670762, condition number = 70.740837607721
   scaling = 0.0785356205378382, condition number = 64.3845928941589
   scaling = 0.0856752224049144, condition number = 59.094895070334
Rescaling to 0.0856752224049144... done
Rescaling...
   scaling = 0.071396018670762, condition number = 70.740837607721
   scaling = 0.0778865658226494, condition number = 64.9139591175929
   scaling = 0.0856752224049144, condition number = 59.094895070334
   scaling = 0.0942427446454058, condition number = 53.8142643746218
   scaling = 0.102810266885897, condition number = 41.540949209166
Rescaling to 0.102810266885897... done
Rescaling...
   scaling = 0.0856752224049144, condition number = 59.094895070334
   scaling = 0.0934638789871793, condition number = 54.2538885770335
   scaling = 0.102810266885897, condition number = 41.540949209166
   scaling = 0.113091293574487, condition number = 31.2901764202367
   scaling = 0.123372320263077, condition number = 24.1712358287144
Rescaling to 0.123372320263077... done
Rescaling...
   scaling = 0.102810266885897, condition number = 41.540949209166
   scaling = 0.112156654784615, condition number = 32.0710890692163
   scaling = 0.123372320263077, condition number = 24.1712358287144
   scaling = 0.135709552289384, condition number = 18.2327382144379
   scaling = 0.148046784315692, condition number = 14.1092826720146
Rescaling to 0.148046784315692... done
Rescaling...
   scaling = 0.123372320263077, condition number = 24.1712358287144
   scaling = 0.134587985741538, condition number = 18.6851158119623
   scaling = 0.148046784315692, condition number = 14.1092826720146
   scaling = 0.162851462747261, condition number = 10.6712025608166
   scaling = 0.17765614117883, condition number = 8.28636871541601
Rescaling to 0.17765614117883... done
Rescaling...
   scaling = 0.148046784315692, condition number = 14.1092826720146
   scaling = 0.161505582889846, condition number = 10.9330030527701
   scaling = 0.17765614117883, condition number = 8.28636871541601
   scaling = 0.195421755296713, condition number = 6.30184716929173
   scaling = 0.213187369414596, condition number = 4.93020486230036
Rescaling to 0.213187369414596... done
Rescaling...
   scaling = 0.17765614117883, condition number = 8.28636871541601
   scaling = 0.193806699467815, condition number = 6.45274379961107
   scaling = 0.213187369414596, condition number = 4.93020486230036
   scaling = 0.234506106356056, condition number = 3.79589970852382
   scaling = 0.255824843297516, condition number = 3.05698177767463
Rescaling to 0.255824843297516... done
Rescaling...
   scaling = 0.213187369414596, condition number = 4.93020486230036
   scaling = 0.232568039361378, condition number = 3.88177261960172
   scaling = 0.255824843297516, condition number = 3.05698177767463
   scaling = 0.281407327627267, condition number = 2.92609920399042
   scaling = 0.306989811957019, condition number = 2.86894872629284
Rescaling to 0.306989811957019... done
Rescaling...
   scaling = 0.255824843297516, condition number = 3.05698177767463
   scaling = 0.279081647233654, condition number = 2.93484421211023
   scaling = 0.306989811957019, condition number = 2.86894872629284
   scaling = 0.337688793152721, condition number = 2.8890138175361
   scaling = 0.368387774348423, condition number = 2.99692316256416
Rescaling to 0.306989811957019... done

		* * * TRAIN ERRORS * * *

_________________Errors report_________________
Energy:
	Errors checked for 100 configurations
	Maximal absolute difference = 0.0322582
	Average absolute difference = 0.0139701
	RMS     absolute difference = 0.0168121

Energy per atom:
	Errors checked for 100 configurations
	Maximal absolute difference = 0.00100807
	Average absolute difference = 0.000436566
	RMS     absolute difference = 0.000525377

Forces:
	Errors checked for 3200 atoms
	Maximal absolute difference = 0.193099
	Average absolute difference = 0.0261683
	RMS     absolute difference = 0.0505307
	Max(ForceDiff) / Max(Force) = 0.12084
	RMS(ForceDiff) / RMS(Force) = 0.138853

Stresses (in eV):
	Errors checked for 100 configurations
	Maximal absolute difference = 2.64457
	Average absolute difference = 0.202276
	RMS     absolute difference = 0.629867
	Max(StresDiff) / Max(Stres) = 0.118813
	RMS(StresDiff) / RMS(Stres) = 0.11028

Stresses (in GPa):
	Errors checked for 100 configurations
	Maximal absolute difference = 0.803096
	Average absolute difference = 0.0614265
	RMS     absolute difference = 0.191276
	Max(StresDiff) / Max(Stres) = 0.118813
	RMS(StresDiff) / RMS(Stres) = 0.11028
_______________________________________________


		* * * VALIDATION ERRORS * * *

_________________Errors report_________________
Energy:
	Errors checked for 1000 configurations
	Maximal absolute difference = 0.0583553
	Average absolute difference = 0.0202303
	RMS     absolute difference = 0.0254796

Energy per atom:
	Errors checked for 1000 configurations
	Maximal absolute difference = 0.0018236
	Average absolute difference = 0.000632198
	RMS     absolute difference = 0.000796237

Forces:
	Errors checked for 32000 atoms
	Maximal absolute difference = 0.222618
	Average absolute difference = 0.0260069
	RMS     absolute difference = 0.0490871
	Max(ForceDiff) / Max(Force) = 0.124735
	RMS(ForceDiff) / RMS(Force) = 0.140378

Stresses (in eV):
	Errors checked for 1000 configurations
	Maximal absolute difference = 3.46746
	Average absolute difference = 0.190278
	RMS     absolute difference = 0.608228
	Max(StresDiff) / Max(Stres) = 0.237018
	RMS(StresDiff) / RMS(Stres) = 0.160337

Stresses (in GPa):
	Errors checked for 1000 configurations
	Maximal absolute difference = 1.05299
	Average absolute difference = 0.0577832
	RMS     absolute difference = 0.184705
	Max(StresDiff) / Max(Stres) = 0.237018
	RMS(StresDiff) / RMS(Stres) = 0.160337
_______________________________________________

