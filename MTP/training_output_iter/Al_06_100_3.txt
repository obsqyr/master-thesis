MTPR from untrained_mtps/06.mtp, Database: cfg_train_eq/Al_train_100_eq_2000.cfg
validation set: cfg_test/Al_test_1000.cfg
Random initialization of radial coefficients
Rescaling...
   scaling = 0.833333333333333, condition number = 626.316900131343
   scaling = 0.909090909090909, condition number = 683.226043374758
   scaling = 1, condition number = 751.519216527323
   scaling = 1.1, condition number = 826.64438837442
   scaling = 1.2, condition number = 901.771678230813
Rescaling to 0.833333333333333... done
Rescaling...
   scaling = 0.694444444444445, condition number = 521.992844813945
   scaling = 0.757575757575758, condition number = 569.411565978741
   scaling = 0.833333333333333, condition number = 626.317396345226
   scaling = 0.916666666666667, condition number = 688.917031314938
   scaling = 1, condition number = 751.519216527007
Rescaling to 0.694444444444445... done
Rescaling...
   scaling = 0.578703703703704, condition number = 435.068071337336
   scaling = 0.631313131313131, condition number = 474.577493349723
   scaling = 0.694444444444445, condition number = 521.992844813945
   scaling = 0.763888888888889, condition number = 574.153591042585
   scaling = 0.833333333333333, condition number = 626.317396345226
Rescaling to 0.578703703703704... done
Rescaling...
   scaling = 0.482253086419753, condition number = 362.64560954317
   scaling = 0.526094276094276, condition number = 395.562701054553
   scaling = 0.578703703703704, condition number = 435.068071337336
   scaling = 0.636574074074074, condition number = 478.528618409465
   scaling = 0.694444444444445, condition number = 521.992844813945
Rescaling to 0.482253086419753... done
Rescaling...
   scaling = 0.401877572016461, condition number = 302.311395647349
   scaling = 0.43841189674523, condition number = 329.733382009593
   scaling = 0.482253086419753, condition number = 362.64560954317
   scaling = 0.530478395061729, condition number = 398.854632434349
   scaling = 0.578703703703704, condition number = 435.068071337336
Rescaling to 0.401877572016461... done
Rescaling...
   scaling = 0.334897976680384, condition number = 252.054342393761
   scaling = 0.365343247287692, condition number = 274.895261375398
   scaling = 0.401877572016461, condition number = 302.311395647349
   scaling = 0.442065329218107, condition number = 332.475846156247
   scaling = 0.482253086419753, condition number = 362.645609669464
Rescaling to 0.334897976680384... done
Rescaling...
   scaling = 0.279081647233653, condition number = 210.199295769713
   scaling = 0.304452706073077, condition number = 229.220466267777
   scaling = 0.334897976680384, condition number = 252.054342393761
   scaling = 0.368387774348423, condition number = 277.179671910051
   scaling = 0.401877572016461, condition number = 302.311395647349
Rescaling to 0.279081647233653... done
Rescaling...
   scaling = 0.232568039361378, condition number = 167.602675255177
   scaling = 0.25371058839423, condition number = 191.186614514286
   scaling = 0.279081647233653, condition number = 210.199295769713
   scaling = 0.306989811957019, condition number = 231.122969311065
   scaling = 0.334897976680384, condition number = 252.054342393761
Rescaling to 0.232568039361378... done
Rescaling...
   scaling = 0.193806699467815, condition number = 116.568174286833
   scaling = 0.211425490328525, condition number = 138.615306012274
   scaling = 0.232568039361378, condition number = 167.602675255177
   scaling = 0.255824843297516, condition number = 192.77061650861
   scaling = 0.279081647233653, condition number = 210.199295769713
Rescaling to 0.193806699467815... done
Rescaling...
   scaling = 0.161505582889846, condition number = 81.1282112931465
   scaling = 0.176187908607104, condition number = 96.4383735938569
   scaling = 0.193806699467815, condition number = 116.568174286833
   scaling = 0.213187369414596, condition number = 140.925470077738
   scaling = 0.232568039361378, condition number = 167.602675255177
Rescaling to 0.161505582889846... done
Rescaling...
   scaling = 0.134587985741538, condition number = 56.518073283606
   scaling = 0.146823257172587, condition number = 67.1496348228909
   scaling = 0.161505582889846, condition number = 81.1282112931465
   scaling = 0.17765614117883, condition number = 98.0426233279636
   scaling = 0.193806699467815, condition number = 116.568174380573
Rescaling to 0.134587985741538... done
Rescaling...
   scaling = 0.112156654784615, condition number = 39.4290558691058
   scaling = 0.122352714310489, condition number = 46.8113790817864
   scaling = 0.134587985741538, condition number = 56.518073283606
   scaling = 0.148046784315692, condition number = 68.26365471953
   scaling = 0.161505582889846, condition number = 81.1282112931465
Rescaling to 0.112156654784615... done
Rescaling...
   scaling = 0.0934638789871793, condition number = 27.5636175768759
   scaling = 0.101960595258741, condition number = 32.6892225594246
   scaling = 0.112156654784615, condition number = 39.4290558691058
   scaling = 0.123372320263077, condition number = 47.5849416719741
   scaling = 0.134587985741538, condition number = 56.518073283606
Rescaling to 0.0934638789871793... done
Rescaling...
   scaling = 0.0778865658226494, condition number = 19.3264740519878
   scaling = 0.0849671627156175, condition number = 22.8844924135254
   scaling = 0.0934638789871793, condition number = 27.5636175768759
   scaling = 0.102810266885897, condition number = 33.2263308032659
   scaling = 0.112156654784615, condition number = 39.4290558691058
Rescaling to 0.0778865658226494... done
Rescaling...
   scaling = 0.0649054715188745, condition number = 13.6101036928432
   scaling = 0.0708059689296813, condition number = 16.0789397377103
   scaling = 0.0778865658226494, condition number = 19.3264740519878
   scaling = 0.0856752224049144, condition number = 23.2573610028254
   scaling = 0.0934638789871793, condition number = 27.5636175603928
Rescaling to 0.0649054715188745... done
Rescaling...
   scaling = 0.0540878929323954, condition number = 9.64580438665095
   scaling = 0.0590049741080677, condition number = 11.3574744894207
   scaling = 0.0649054715188745, condition number = 13.6101036928432
   scaling = 0.071396018670762, condition number = 16.3377006597174
   scaling = 0.0778865658226494, condition number = 19.3264740695957
Rescaling to 0.0540878929323954... done
Rescaling...
   scaling = 0.0450732441103295, condition number = 6.90025980798085
   scaling = 0.0491708117567231, condition number = 8.08507893312605
   scaling = 0.0540878929323954, condition number = 9.64580438665095
   scaling = 0.059496682225635, condition number = 11.5369247767386
   scaling = 0.0649054715188745, condition number = 13.6101036928432
Rescaling to 0.0450732441103295... done
Rescaling...
   scaling = 0.0375610367586079, condition number = 5.00367821056386
   scaling = 0.0409756764639359, condition number = 5.82131315461381
   scaling = 0.0450732441103295, condition number = 6.90025980798085
   scaling = 0.0495805685213625, condition number = 8.2093596250143
   scaling = 0.0540878929323954, condition number = 9.64580439749207
Rescaling to 0.0375610367586079... done
Rescaling...
   scaling = 0.0313008639655066, condition number = 3.69979901877917
   scaling = 0.03414639705328, condition number = 4.26088464033714
   scaling = 0.0375610367586079, condition number = 5.00367821056386
   scaling = 0.0413171404344687, condition number = 5.90716283476124
   scaling = 0.0450732441103295, condition number = 6.90025980798085
Rescaling to 0.0313008639655066... done
Rescaling...
   scaling = 0.0260840533045889, condition number = 2.8110056126426
   scaling = 0.0284553308777333, condition number = 3.19224601382404
   scaling = 0.0313008639655066, condition number = 3.69979901877917
   scaling = 0.0344309503620573, condition number = 4.31990280799025
   scaling = 0.0375610367586079, condition number = 5.00367821056386
Rescaling to 0.0260840533045889... done
Rescaling...
   scaling = 0.0217367110871574, condition number = 2.21390513433184
   scaling = 0.0237127757314444, condition number = 2.46864772382256
   scaling = 0.0260840533045889, condition number = 2.8110056126426
   scaling = 0.0286924586350477, condition number = 3.23247153817263
   scaling = 0.0313008639655066, condition number = 3.69979901877917
Rescaling to 0.0217367110871574... done
Rescaling...
   scaling = 0.0181139259059645, condition number = 1.82232585255746
   scaling = 0.0197606464428703, condition number = 1.98789149223877
   scaling = 0.0217367110871574, condition number = 2.21390513433184
   scaling = 0.0239103821958731, condition number = 2.49566547566863
   scaling = 0.0260840533045889, condition number = 2.8110056126426
Rescaling to 0.0181139259059645... done
Rescaling...
   scaling = 0.0150949382549704, condition number = 2.23959128808806
   scaling = 0.0164672053690586, condition number = 2.00435526116063
   scaling = 0.0181139259059645, condition number = 1.82232585255746
   scaling = 0.0199253184965609, condition number = 2.00560229829161
   scaling = 0.0217367110871574, condition number = 2.21390513556754
Rescaling to 0.0181139259059645... done
Pre-training started
MTPR parallel training started
BFGS iter 0: f=0.00422436
BFGS iter 1: f=0.00421238
BFGS iter 2: f=0.00417236
BFGS iter 3: f=0.00372718
BFGS iter 4: f=0.00361341
BFGS iter 5: f=0.00354038
BFGS iter 6: f=0.00346216
BFGS iter 7: f=0.00337648
BFGS iter 8: f=0.00333746
BFGS iter 9: f=0.0033113
BFGS iter 10: f=0.0032797
BFGS iter 11: f=0.00326178
BFGS iter 12: f=0.0032585
BFGS iter 13: f=0.00325555
BFGS iter 14: f=0.00325289
BFGS iter 15: f=0.00324167
BFGS iter 16: f=0.00323097
BFGS iter 17: f=0.003228
BFGS iter 18: f=0.00322623
BFGS iter 19: f=0.00322399
BFGS iter 20: f=0.00321763
BFGS iter 21: f=0.00319917
BFGS iter 22: f=0.0031893
BFGS iter 23: f=0.00318524
BFGS iter 24: f=0.00318165
BFGS iter 25: f=0.00317937
BFGS iter 26: f=0.00317759
BFGS iter 27: f=0.00317617
BFGS iter 28: f=0.00317525
BFGS iter 29: f=0.00317387
BFGS iter 30: f=0.00317206
BFGS iter 31: f=0.00316951
BFGS iter 32: f=0.00316687
BFGS iter 33: f=0.00316347
BFGS iter 34: f=0.00315113
BFGS iter 35: f=0.0031245
BFGS iter 36: f=0.0031159
BFGS iter 37: f=0.0030812
BFGS iter 38: f=0.00305738
BFGS iter 39: f=0.00304323
BFGS iter 40: f=0.0030382
BFGS iter 41: f=0.00303584
BFGS iter 42: f=0.00303473
BFGS iter 43: f=0.00303349
BFGS iter 44: f=0.00303236
BFGS iter 45: f=0.00302997
BFGS iter 46: f=0.00302568
BFGS iter 47: f=0.00301558
BFGS iter 48: f=0.00301051
BFGS iter 49: f=0.00300069
BFGS iter 50: f=0.00297548
BFGS iter 51: f=0.00297028
BFGS iter 52: f=0.00297001
BFGS iter 53: f=0.00296677
BFGS iter 54: f=0.00296611
BFGS iter 55: f=0.00296588
BFGS iter 56: f=0.00296487
BFGS iter 57: f=0.00296418
BFGS iter 58: f=0.0029625
BFGS iter 59: f=0.002962
BFGS iter 60: f=0.00296177
BFGS iter 61: f=0.00296128
BFGS iter 62: f=0.00295849
BFGS iter 63: f=0.00294717
BFGS iter 64: f=0.00294367
BFGS iter 65: f=0.00293677
BFGS iter 66: f=0.00293349
BFGS iter 67: f=0.00293175
BFGS iter 68: f=0.00293013
BFGS iter 69: f=0.00292714
BFGS iter 70: f=0.00292655
BFGS iter 71: f=0.00292565
BFGS iter 72: f=0.00292541
BFGS iter 73: f=0.00292533
BFGS iter 74: f=0.0029253
step limit reached
MTPR training ended
Rescaling...
   scaling = 0.0150949382549704, condition number = 3.88680995168053
   scaling = 0.0164672053690586, condition number = 4.11993226911462
   scaling = 0.0181139259059645, condition number = 4.42464103663523
   scaling = 0.0199253184965609, condition number = 4.7810119200397
   scaling = 0.0217367110871574, condition number = 5.15218727417035
Rescaling to 0.0150949382549704... done
Rescaling...
   scaling = 0.0125791152124753, condition number = 3.54036113142216
   scaling = 0.0137226711408822, condition number = 3.68139176181978
   scaling = 0.0150949382549704, condition number = 3.88681018816891
   scaling = 0.0166044320804674, condition number = 4.14441709934308
   scaling = 0.0181139259059645, condition number = 4.42464103650467
Rescaling to 0.0125791152124753... done
Rescaling...
   scaling = 0.0104825960103961, condition number = 3.39312604544433
   scaling = 0.0114355592840685, condition number = 3.4380189264014
   scaling = 0.0125791152124753, condition number = 3.54036113142216
   scaling = 0.0138370267337229, condition number = 3.69717785353745
   scaling = 0.0150949382549704, condition number = 3.88681018816891
Rescaling to 0.0104825960103961... done
Rescaling...
   scaling = 0.00873549667533009, condition number = 3.45108520029068
   scaling = 0.00952963273672374, condition number = 3.39774255779968
   scaling = 0.0104825960103961, condition number = 3.39312604544433
   scaling = 0.0115308556114357, condition number = 3.44473358355753
   scaling = 0.0125791152124753, condition number = 3.54036113142216
Rescaling to 0.0104825960103961... done
Pre-training ended
BFGS iterations count set to 1000
BFGS convergence tolerance set to 0.001
Energy weight: 1
Force weight: 0.01
Stress weight: 0.001
MTPR parallel training started
BFGS iter 0: f=0.00291206
BFGS iter 1: f=0.00291205
BFGS iter 2: f=0.00291173
BFGS iter 3: f=0.00291085
BFGS iter 4: f=0.00290391
BFGS iter 5: f=0.00289759
BFGS iter 6: f=0.00289043
BFGS iter 7: f=0.00288851
BFGS iter 8: f=0.00288692
BFGS iter 9: f=0.00288488
BFGS iter 10: f=0.00288261
BFGS iter 11: f=0.00287819
BFGS iter 12: f=0.00286384
BFGS iter 13: f=0.00285423
BFGS iter 14: f=0.00284687
BFGS iter 15: f=0.00284479
BFGS iter 16: f=0.00284261
BFGS iter 17: f=0.00284212
BFGS iter 18: f=0.00284198
BFGS iter 19: f=0.00284196
BFGS iter 20: f=0.00284193
BFGS iter 21: f=0.0028407
BFGS iter 22: f=0.00283923
BFGS iter 23: f=0.0028383
BFGS iter 24: f=0.00283816
BFGS iter 25: f=0.00283808
BFGS iter 26: f=0.00283754
BFGS iter 27: f=0.00283615
BFGS iter 28: f=0.0028342
BFGS iter 29: f=0.00283261
BFGS iter 30: f=0.00283166
BFGS iter 31: f=0.00283111
BFGS iter 32: f=0.00283091
BFGS iter 33: f=0.00283077
BFGS iter 34: f=0.00283067
BFGS iter 35: f=0.00283059
BFGS iter 36: f=0.00283048
BFGS iter 37: f=0.00283029
BFGS iter 38: f=0.00282905
BFGS iter 39: f=0.00282552
BFGS iter 40: f=0.00282449
BFGS iter 41: f=0.00282119
BFGS iter 42: f=0.00282013
BFGS iter 43: f=0.00281982
BFGS iter 44: f=0.00281949
BFGS iter 45: f=0.00281926
BFGS iter 46: f=0.00281908
BFGS iter 47: f=0.00281889
BFGS iter 48: f=0.00281862
BFGS iter 49: f=0.00281598
BFGS iter 50: f=0.00280811
BFGS iter 51: f=0.00280795
BFGS iter 52: f=0.00280723
BFGS iter 53: f=0.00280564
BFGS iter 54: f=0.00280362
BFGS iter 55: f=0.00280319
BFGS iter 56: f=0.0028024
BFGS iter 57: f=0.00280201
BFGS iter 58: f=0.00280188
BFGS iter 59: f=0.00280171
BFGS iter 60: f=0.00280151
BFGS iter 61: f=0.00280134
BFGS iter 62: f=0.00280127
BFGS iter 63: f=0.00280125
BFGS iter 64: f=0.00280124
BFGS iter 65: f=0.0028012
BFGS iter 66: f=0.00280053
BFGS iter 67: f=0.00279922
BFGS iter 68: f=0.00279848
BFGS iter 69: f=0.00279818
BFGS iter 70: f=0.00279783
BFGS iter 71: f=0.0027975
BFGS iter 72: f=0.00279702
BFGS iter 73: f=0.00279659
BFGS iter 74: f=0.00279628
BFGS iter 75: f=0.0027958
BFGS iter 76: f=0.00279558
BFGS iter 77: f=0.0027954
BFGS iter 78: f=0.00279514
BFGS iter 79: f=0.00279478
BFGS iter 80: f=0.00279429
BFGS iter 81: f=0.00279386
BFGS iter 82: f=0.00279335
BFGS iter 83: f=0.00279311
BFGS iter 84: f=0.00279285
BFGS iter 85: f=0.00279249
BFGS iter 86: f=0.00279223
BFGS iter 87: f=0.00279201
BFGS iter 88: f=0.00279159
BFGS iter 89: f=0.00279055
BFGS iter 90: f=0.00278997
BFGS iter 91: f=0.00278932
BFGS iter 92: f=0.00278813
BFGS iter 93: f=0.00278691
BFGS iter 94: f=0.00278323
BFGS iter 95: f=0.00278255
BFGS iter 96: f=0.00278036
BFGS iter 97: f=0.00277822
BFGS iter 98: f=0.00277734
BFGS iter 99: f=0.00277681
BFGS iter 100: f=0.00277519
BFGS iter 101: f=0.00277502
BFGS iter 102: f=0.00277473
BFGS iter 103: f=0.00277457
BFGS iter 104: f=0.00277437
BFGS iter 105: f=0.00277406
BFGS iter 106: f=0.00277399
BFGS iter 107: f=0.00277391
BFGS iter 108: f=0.00277378
BFGS iter 109: f=0.00277374
BFGS iter 110: f=0.00277367
BFGS iter 111: f=0.00277357
BFGS iter 112: f=0.00277345
BFGS iter 113: f=0.00277341
BFGS iter 114: f=0.00277337
BFGS iter 115: f=0.00277333
BFGS iter 116: f=0.00277327
BFGS iter 117: f=0.00277309
BFGS iter 118: f=0.0027728
BFGS iter 119: f=0.00277112
BFGS iter 120: f=0.0027691
BFGS iter 121: f=0.00276658
BFGS iter 122: f=0.00276334
BFGS iter 123: f=0.0027626
BFGS iter 124: f=0.00276158
BFGS iter 125: f=0.00276126
BFGS iter 126: f=0.00276107
BFGS iter 127: f=0.002761
BFGS iter 128: f=0.00276095
BFGS iter 129: f=0.00276088
BFGS iter 130: f=0.0027608
BFGS iter 131: f=0.0027603
BFGS iter 132: f=0.00275995
BFGS iter 133: f=0.00275948
BFGS iter 134: f=0.002759
BFGS iter 135: f=0.0027584
BFGS iter 136: f=0.00275818
BFGS iter 137: f=0.00275799
BFGS iter 138: f=0.0027579
BFGS iter 139: f=0.00275782
BFGS iter 140: f=0.0027578
BFGS iter 141: f=0.00275779
BFGS iter 142: f=0.00275779
BFGS iter 143: f=0.00275779
BFGS iter 144: f=0.00275779
BFGS iter 145: f=0.00275777
BFGS iter 146: f=0.00275776
BFGS iter 147: f=0.00275776
BFGS iter 148: f=0.00275775
BFGS iter 149: f=0.00275767
BFGS iter 150: f=0.00275728
BFGS iter 151: f=0.00275721
BFGS iter 152: f=0.00275717
BFGS iter 153: f=0.00275714
BFGS iter 154: f=0.00275713
BFGS iter 155: f=0.00275712
BFGS iter 156: f=0.00275711
BFGS iter 157: f=0.00275711
BFGS iter 158: f=0.0027571
BFGS iter 159: f=0.00275706
BFGS iter 160: f=0.00275691
BFGS iter 161: f=0.00275685
BFGS iter 162: f=0.00275682
BFGS iter 163: f=0.0027568
BFGS iter 164: f=0.00275675
BFGS iter 165: f=0.00275653
BFGS iter 166: f=0.00275642
BFGS iter 167: f=0.00275638
BFGS iter 168: f=0.00275634
BFGS iter 169: f=0.00275632
BFGS iter 170: f=0.00275631
BFGS iter 171: f=0.00275631
BFGS iter 172: f=0.00275631
BFGS iter 173: f=0.00275631
BFGS iter 174: f=0.00275631
BFGS iter 175: f=0.00275629
BFGS iter 176: f=0.00275622
BFGS iter 177: f=0.00275605
BFGS iter 178: f=0.00275598
BFGS iter 179: f=0.00275595
BFGS iter 180: f=0.00275592
BFGS iter 181: f=0.00275591
BFGS iter 182: f=0.0027559
BFGS iter 183: f=0.0027559
BFGS iter 184: f=0.0027559
BFGS iter 185: f=0.0027559
BFGS iter 186: f=0.0027559
BFGS iter 187: f=0.00275589
BFGS iter 188: f=0.00275577
BFGS iter 189: f=0.00275562
BFGS iter 190: f=0.00275545
BFGS iter 191: f=0.00275536
BFGS iter 192: f=0.00275514
BFGS iter 193: f=0.00275505
BFGS iter 194: f=0.00275485
BFGS iter 195: f=0.00275474
BFGS iter 196: f=0.00275472
BFGS iter 197: f=0.00275469
BFGS iter 198: f=0.00275467
BFGS iter 199: f=0.00275467
BFGS ended due to small decr. in 50 iterations
MTPR training ended
Rescaling...
   scaling = 0.00873549667533009, condition number = 6.0586068114099
   scaling = 0.00952963273672374, condition number = 5.5996404786486
   scaling = 0.0104825960103961, condition number = 5.14611520110373
   scaling = 0.0115308556114357, condition number = 4.74054077529836
   scaling = 0.0125791152124753, condition number = 4.40969060925203
Rescaling to 0.0125791152124753... done
Rescaling...
   scaling = 0.0104825960103961, condition number = 5.14611520110373
   scaling = 0.0114355592840685, condition number = 4.77402743567563
   scaling = 0.0125791152124753, condition number = 4.40969060925203
   scaling = 0.0138370267337229, condition number = 4.08856202615126
   scaling = 0.0150949382549704, condition number = 3.83226247725296
Rescaling to 0.0150949382549704... done
Rescaling...
   scaling = 0.0125791152124753, condition number = 4.40969060925203
   scaling = 0.0137226711408822, condition number = 4.11483952109209
   scaling = 0.0150949382549704, condition number = 3.83226247725296
   scaling = 0.0166044320804674, condition number = 3.59223735658754
   scaling = 0.0181139259059645, condition number = 3.41201897348137
Rescaling to 0.0181139259059645... done
Rescaling...
   scaling = 0.0150949382549704, condition number = 3.83226247725296
   scaling = 0.0164672053690586, condition number = 3.61140627873982
   scaling = 0.0181139259059645, condition number = 3.41201897348137
   scaling = 0.0199253184965609, condition number = 3.1587264365218
   scaling = 0.0217367110871574, condition number = 2.58159158901399
Rescaling to 0.0217367110871574... done
Rescaling...
   scaling = 0.0181139259059645, condition number = 3.41201897348137
   scaling = 0.0197606464428703, condition number = 3.22245870004922
   scaling = 0.0217367110871574, condition number = 2.58159158901399
   scaling = 0.0239103821958731, condition number = 2.200337557613
   scaling = 0.0260840533045889, condition number = 2.22525596931183
Rescaling to 0.0239103821958731... done
Rescaling...
   scaling = 0.0199253184965609, condition number = 3.15872645377324
   scaling = 0.0217367110871574, condition number = 2.58159158901399
   scaling = 0.0239103821958731, condition number = 2.200337557613
   scaling = 0.0263014204154604, condition number = 2.23030995648899
   scaling = 0.0286924586350477, condition number = 2.31474696353242
Rescaling to 0.0239103821958731... done

		* * * TRAIN ERRORS * * *

_________________Errors report_________________
Energy:
	Errors checked for 100 configurations
	Maximal absolute difference = 0.0232247
	Average absolute difference = 0.00779261
	RMS     absolute difference = 0.0100119

Energy per atom:
	Errors checked for 100 configurations
	Maximal absolute difference = 0.00072577
	Average absolute difference = 0.000243519
	RMS     absolute difference = 0.000312872

Forces:
	Errors checked for 3200 atoms
	Maximal absolute difference = 0.252113
	Average absolute difference = 0.0273198
	RMS     absolute difference = 0.0518413
	Max(ForceDiff) / Max(Force) = 0.161476
	RMS(ForceDiff) / RMS(Force) = 0.145365

Stresses (in eV):
	Errors checked for 100 configurations
	Maximal absolute difference = 4.27877
	Average absolute difference = 0.231155
	RMS     absolute difference = 0.780135
	Max(StresDiff) / Max(Stres) = 0.335188
	RMS(StresDiff) / RMS(Stres) = 0.210092

Stresses (in GPa):
	Errors checked for 100 configurations
	Maximal absolute difference = 1.29936
	Average absolute difference = 0.0701964
	RMS     absolute difference = 0.236909
	Max(StresDiff) / Max(Stres) = 0.335188
	RMS(StresDiff) / RMS(Stres) = 0.210092
_______________________________________________


		* * * VALIDATION ERRORS * * *

_________________Errors report_________________
Energy:
	Errors checked for 1000 configurations
	Maximal absolute difference = 0.0787177
	Average absolute difference = 0.0310945
	RMS     absolute difference = 0.0370022

Energy per atom:
	Errors checked for 1000 configurations
	Maximal absolute difference = 0.00245993
	Average absolute difference = 0.000971704
	RMS     absolute difference = 0.00115632

Forces:
	Errors checked for 32000 atoms
	Maximal absolute difference = 0.224551
	Average absolute difference = 0.0265371
	RMS     absolute difference = 0.0500215
	Max(ForceDiff) / Max(Force) = 0.125819
	RMS(ForceDiff) / RMS(Force) = 0.143051

Stresses (in eV):
	Errors checked for 1000 configurations
	Maximal absolute difference = 3.18091
	Average absolute difference = 0.181805
	RMS     absolute difference = 0.5759
	Max(StresDiff) / Max(Stres) = 0.217431
	RMS(StresDiff) / RMS(Stres) = 0.151815

Stresses (in GPa):
	Errors checked for 1000 configurations
	Maximal absolute difference = 0.96597
	Average absolute difference = 0.0552098
	RMS     absolute difference = 0.174887
	Max(StresDiff) / Max(Stres) = 0.217431
	RMS(StresDiff) / RMS(Stres) = 0.151815
_______________________________________________

